{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1bb85bb",
   "metadata": {},
   "source": [
    "Sources:\n",
    "https://platform.openai.com/docs/guides/fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087f0ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91ba154",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Cat_0_Data/data/Cat_0_commonexample.yaml') as f:\n",
    "    data = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa2aff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_examples(examples: str) -> list[str]:\n",
    "    \"\"\"Converts examples from YAML file to list of utterance texts\n",
    "\n",
    "    Args:\n",
    "        examples (string): Examples from YAML data file.\n",
    "                           It is a single string containing all utterances\n",
    "                           separated by '\\n- '\n",
    "\n",
    "    Returns:\n",
    "        List[str]: list of utterance texts\n",
    "    \"\"\"\n",
    "\n",
    "    texts = [text.strip() for text in examples.lstrip(\"- \").split(\"\\n- \")]\n",
    "    # splitting by '\\n -' causes empty string to be present in the list,\n",
    "    # in case the value of examples is ''.\n",
    "    if \"\" in texts:\n",
    "        texts.remove(\"\")\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b208634b",
   "metadata": {},
   "source": [
    "A prompt separator string needs to be added at the end of the prompt both while fine tuning and sending requests to the model. Else, the outputted completions would most likely be random, instead of our desired output intents. This separator should NOT be present in the utterance at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e2c966db",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_separator = \"\\n\\nIntent:\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb4613",
   "metadata": {},
   "source": [
    "Completions should start with a whitespace since OpenAI's tokenization tokenizes most words with a preceding whitespace.\n",
    "\n",
    "For classification tasks, OpenAI recommends us to choose classes which map to a single token and set max_tokens=1. But some classes like \"Enquiry\" or \"Incident\" map to multiple tokens. So, we set a stop sequence at the end of the completion instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_stop_sequence = \" END\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8766d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = []\n",
    "\n",
    "for intent_dict in data['nlu']:\n",
    "    intent = intent_dict['intent']\n",
    "    examples = parse_examples(intent_dict['examples'])\n",
    "    for example in examples[:40]:\n",
    "        json_list.append({'prompt': f'{example}{prompt_separator}', \n",
    "                          'completion': f' {intent}{completion_stop_sequence}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e8914570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b24a0884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "95feab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('data_new.jsonl', mode='w') as writer:\n",
    "    # Write each data item as a separate line\n",
    "    for item in json_list:\n",
    "        writer.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2ecc2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2645447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.1k/17.1k [00:00<00:00, 20.6Mit/s]\n",
      "Uploaded file from data_new.jsonl: file-EVRMo8oO1Az4m6TM3zBfXLRs\n",
      "Created fine-tune: ft-uUWLxtby9xSUbzFaEXxBC6FZ\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2023-06-28 15:09:16] Created fine-tune: ft-uUWLxtby9xSUbzFaEXxBC6FZ\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-uUWLxtby9xSUbzFaEXxBC6FZ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.create -t data_new.jsonl -m ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6763b9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-28 15:09:16] Created fine-tune: ft-uUWLxtby9xSUbzFaEXxBC6FZ\n",
      "[2023-06-28 15:50:00] Fine-tune costs $0.01\n",
      "[2023-06-28 15:50:01] Fine-tune enqueued. Queue number: 5\n",
      "[2023-06-28 15:50:12] Fine-tune is in the queue. Queue number: 4\n",
      "[2023-06-28 15:51:09] Fine-tune is in the queue. Queue number: 3\n",
      "[2023-06-28 15:52:08] Fine-tune is in the queue. Queue number: 2\n",
      "[2023-06-28 15:52:38] Fine-tune is in the queue. Queue number: 1\n",
      "[2023-06-28 15:52:52] Fine-tune is in the queue. Queue number: 0\n",
      "[2023-06-28 15:52:54] Fine-tune started\n",
      "[2023-06-28 15:53:26] Completed epoch 1/4\n",
      "[2023-06-28 15:53:44] Completed epoch 2/4\n",
      "[2023-06-28 15:54:02] Completed epoch 3/4\n",
      "[2023-06-28 15:54:20] Completed epoch 4/4\n",
      "[2023-06-28 15:54:36] Uploaded model: ada:ft-personal-2023-06-28-10-24-36\n",
      "[2023-06-28 15:55:17] Uploaded result file: file-gbizTYbB1ufAYFGhc2dJjF82\n",
      "[2023-06-28 15:55:17] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded ðŸŽ‰\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m ada:ft-personal-2023-06-28-10-24-36 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.follow -i ft-uUWLxtby9xSUbzFaEXxBC6FZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "63da4d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "response = openai.Completion.create(\n",
    "    model=\"ada:ft-personal-2023-06-28-10-24-36\",\n",
    "    prompt=f\"Help! I got logged out of my outlook account due to issues in MFA{prompt_separator}\",\n",
    "    stop=[completion_stop_sequence]\n",
    ")\n",
    "print(response['choices'][0]['text'].strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
