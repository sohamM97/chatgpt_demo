{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1bb85bb",
   "metadata": {},
   "source": [
    "Sources:\n",
    "https://platform.openai.com/docs/guides/fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "087f0ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e91ba154",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/nlu_converted.yml') as f:\n",
    "    data = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2aff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_examples(examples: str) -> list[str]:\n",
    "    \"\"\"Converts examples from YAML file to list of utterance texts\n",
    "\n",
    "    Args:\n",
    "        examples (string): Examples from YAML data file.\n",
    "                           It is a single string containing all utterances\n",
    "                           separated by '\\n- '\n",
    "\n",
    "    Returns:\n",
    "        List[str]: list of utterance texts\n",
    "    \"\"\"\n",
    "\n",
    "    texts = [text.strip() for text in examples.lstrip(\"- \").split(\"\\n- \")]\n",
    "    # splitting by '\\n -' causes empty string to be present in the list,\n",
    "    # in case the value of examples is ''.\n",
    "    if \"\" in texts:\n",
    "        texts.remove(\"\")\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57e92651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_entities_from_text(text: str) -> tuple[str, list]:\n",
    "    \"\"\"Lists labelled entities from texts and returns list of entities\n",
    "    along with original text.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text with labelled entities\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, List[MappedEntitiesDict]]: Tuple containing\n",
    "            original text and list of mapped entities\n",
    "    \"\"\"\n",
    "\n",
    "    # The following regex pattern detects whether utterance\n",
    "    # is labelled with entities\n",
    "    # Group 1: (\\[.+?\\]) [entity value]\n",
    "    # Group 2: ({\\s*\\\"entity\\\":\\s*\\\".+?\\\"\\s*}) (entity name)\n",
    "    # Example: Book flight from [pune](city_name) to [mumbai](city_name)\n",
    "    entity_regex_pattern_1 = r\"(\\[.+?\\])(\\(.+?\\))\"\n",
    "\n",
    "    # The following regex pattern detects whether utterance\n",
    "    # is labelled with entities (may or may not contain roles)\n",
    "    # Group 1: (\\[.+?\\]) [entity value]\n",
    "    # Group 2: ({\\s*\\\"entity\\\":\\s*\\\".+?\\\"\\s*})\n",
    "    #          {\"entity\": \"entity name\", \"role\": \"role name (optional)\"}\n",
    "    # Example: Book flight from [pune]{\"entity\": \"city_name\", \"role\": \"source\"}\n",
    "    #          to [mumbai]{\"entity\": \"city_name\", \"role\": \"destination\"}\n",
    "    entity_regex_pattern_2 = r\"(\\[.+?\\])({\\s*\\\"entity\\\":\\s*\\\".+?\\\"\\s*})\"\n",
    "\n",
    "    # utterance after removing labelled entities (if any)\n",
    "    text_without_entities = text\n",
    "\n",
    "    mapped_entities = []\n",
    "\n",
    "    for entity_regex_pattern in [entity_regex_pattern_1, entity_regex_pattern_2]:\n",
    "        for _ in range(len(re.findall(entity_regex_pattern, text))):\n",
    "\n",
    "            match = re.search(entity_regex_pattern, text_without_entities)\n",
    "\n",
    "            entity_value = match.group(1)\n",
    "            entity_value = entity_value[1:-1]  # removing square brackets []\n",
    "\n",
    "            if entity_regex_pattern == entity_regex_pattern_1:\n",
    "                entity_name = match.group(2)\n",
    "                entity_name = entity_name[1:-1]  # removing brackets ()\n",
    "                role_name = None  # not provided\n",
    "\n",
    "            elif entity_regex_pattern == entity_regex_pattern_2:\n",
    "                entity_dict = match.group(2)\n",
    "                entity_dict = json.loads(entity_dict)\n",
    "                entity_name = entity_dict[\"entity\"]\n",
    "                role_name = entity_dict.get(\"role\")\n",
    "\n",
    "            # removing the labelled entity and role from the text\n",
    "            text_without_entities = (\n",
    "                text_without_entities[: match.start()]\n",
    "                + entity_value\n",
    "                + text_without_entities[match.end() :]\n",
    "            )\n",
    "\n",
    "            # start and end position of utterance to entity mapping\n",
    "            start = match.start(1)\n",
    "            end = match.end(1) - 2  # since [ and ] are removed\n",
    "\n",
    "            mapped_entities.append(\n",
    "                {\n",
    "                    \"name\": entity_name,\n",
    "                    \"value\": entity_value,\n",
    "                    \"role_name\": role_name,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return text_without_entities, mapped_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b208634b",
   "metadata": {},
   "source": [
    "A prompt separator string needs to be added at the end of the prompt both while fine tuning and sending requests to the model. Else, the outputted completions would most likely be random, instead of our desired output intents. This separator should NOT be present in the utterance at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2c966db",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_separator = \"\\n\\nNLU_RESULTS:\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb4613",
   "metadata": {},
   "source": [
    "Completions should start with a whitespace since OpenAI's tokenization tokenizes most words with a preceding whitespace.\n",
    "\n",
    "For classification tasks, OpenAI recommends us to choose classes which map to a single token and set max_tokens=1. But some classes like \"Enquiry\" or \"Incident\" map to multiple tokens. So, we set a stop sequence at the end of the completion instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "089a017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_stop_sequence = \" END\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8766d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = []\n",
    "\n",
    "for intent_dict in data['nlu']:\n",
    "    intent = intent_dict['intent']\n",
    "    examples = parse_examples(intent_dict['examples'])\n",
    "    for example in examples[:40]:\n",
    "        example, entities_dict = parse_entities_from_text(example)\n",
    "        prompt = f'{example}{prompt_separator}'\n",
    "        completion_dict = json.dumps({'intent': intent, 'entities': entities_dict})\n",
    "        completion = f' {completion_dict}{completion_stop_sequence}'\n",
    "        json_list.append({'prompt': prompt, \n",
    "                          'completion': completion})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbb675e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Hello. I need help setting up a distribution list\\n\\nNLU_RESULTS:\\n\\n',\n",
       " 'completion': ' {\"intent\": \"DLEmail\", \"entities\": [{\"name\": \"Software_Attribute\", \"value\": \"distribution list\", \"role_name\": null}]} END'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8914570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b24a0884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95feab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('intent_entity.jsonl', mode='w') as writer:\n",
    "    # Write each data item as a separate line\n",
    "    for item in json_list:\n",
    "        writer.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2ecc2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2645447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85.1k/85.1k [00:00<00:00, 37.0Mit/s]\n",
      "Uploaded file from intent_entity.jsonl: file-d8LXQqks694NOHLlb8cuU2VR\n",
      "Created fine-tune: ft-h6nHAGr4G6u4JtDkswE412vP\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2023-06-28 17:56:49] Created fine-tune: ft-h6nHAGr4G6u4JtDkswE412vP\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-h6nHAGr4G6u4JtDkswE412vP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.create -t intent_entity.jsonl -m ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6763b9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-28 17:56:49] Created fine-tune: ft-h6nHAGr4G6u4JtDkswE412vP\n",
      "[2023-06-28 18:45:50] Fine-tune costs $0.03\n",
      "[2023-06-28 18:45:50] Fine-tune enqueued. Queue number: 6\n",
      "[2023-06-28 18:48:35] Fine-tune is in the queue. Queue number: 5\n",
      "[2023-06-28 18:49:50] Fine-tune is in the queue. Queue number: 4\n",
      "[2023-06-28 18:49:52] Fine-tune is in the queue. Queue number: 3\n",
      "[2023-06-28 18:49:57] Fine-tune is in the queue. Queue number: 2\n",
      "[2023-06-28 18:50:08] Fine-tune is in the queue. Queue number: 1\n",
      "[2023-06-28 18:51:12] Fine-tune is in the queue. Queue number: 0\n",
      "[2023-06-28 18:51:14] Fine-tune started\n",
      "[2023-06-28 18:52:12] Completed epoch 1/4\n",
      "[2023-06-28 18:52:57] Completed epoch 2/4\n",
      "[2023-06-28 18:53:42] Completed epoch 3/4\n",
      "[2023-06-28 18:54:26] Completed epoch 4/4\n",
      "[2023-06-28 18:54:47] Uploaded model: ada:ft-personal-2023-06-28-13-24-46\n",
      "[2023-06-28 18:55:08] Uploaded result file: file-iAhYpNQzwMcTosPS8kQBUD5G\n",
      "[2023-06-28 18:55:08] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded ðŸŽ‰\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m ada:ft-personal-2023-06-28-13-24-46 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.follow -i ft-h6nHAGr4G6u4JtDkswE412vP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "63da4d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"intent\": \"Hardware&Peripheral\", \"entities\": [{\"name\": \"Hardware_Peripheral\", \"value\": \"new laptop battery\", \"role_name\": null}]}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "response = openai.Completion.create(\n",
    "    model=\"ada:ft-personal-2023-06-28-13-24-46\",\n",
    "    prompt=f\"I need new laptop battery{prompt_separator}\",\n",
    "    max_tokens=1000,\n",
    "    stop=[completion_stop_sequence]\n",
    ")\n",
    "print(response['choices'][0]['text'].strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
